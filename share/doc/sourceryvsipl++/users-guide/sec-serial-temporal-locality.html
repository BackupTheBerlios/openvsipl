<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>7.2. Serial Optimization: Temporal Locality</title><link rel="stylesheet" href="cs.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"><link rel="home" href="index.html" title="Sourcery VSIPL++"><link rel="up" href="chap-serial.html" title="Chapter 7. Fast Convolution"><link rel="prev" href="chap-serial.html" title="Chapter 7. Fast Convolution"><link rel="next" href="sec-io-user-spec-storage.html" title="7.3. Performing I/O with User-Specified Storage"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">7.2. Serial Optimization: Temporal Locality</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="chap-serial.html">Prev</a> </td><th width="60%" align="center">Chapter 7. Fast Convolution</th><td width="20%" align="right"> <a accesskey="n" href="sec-io-user-spec-storage.html">Next</a></td></tr></table><hr></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sec-serial-temporal-locality"></a>7.2. Serial Optimization: Temporal Locality</h2></div></div></div><p>
   In this section, you will learn how to improve the performance of
   fast convolution by improving <em class="firstterm">temporal locality</em>,
   i.e., by making accesses to the same memory locations occur near the
   same time.
  </p><p>
   The code in <a class="xref" href="chap-serial.html#sec-serial-fastconv" title="7.1. Fast Convolution">Section 7.1, &#8220;Fast Convolution&#8221;</a> performs a FFT on
   each row of the matrix.  Then, after all the rows have been
   processed, it multiplies each row of the matrix by the
   <code class="varname">replica</code>.  Suppose that there are a large number
   of rows, so that <code class="varname">data</code> is too large to fit in
   cache.  In that case, while the results of the first FFT will be in
   cache immediately after the FFT is complete, that data will likey
   have been purged from the cache by the time the vector-matrix
   multiply needs the data.
  </p><p>
   Explicitly iterating over the rows of the matrix (performing a
   forward FFT, elementwise multiplication, and an inverse FFT on each
   row before going on to the next one) will improve temporal
   locality.  You can use this approach by using an explicit loop,
   rather than the implicit parallelism of <code class="function">Fftm</code>
   and <code class="function">vmmul</code>, to take better advantage of the
   cache.
  </p><p>
   You must make a few changes to the application in order to
   implement this approach.  Because the application will be operating
   on only a single row at a time, <code class="function">Fftm</code> must be
   replaced with the simpler <code class="function">Fft</code>.  Similarly,
   <code class="function">vmmul</code> must be replaced with
   <code class="function">*</code>, which performs element-wise multiplication
   of its operands.  Finally, <code class="varname">tmp</code> can now be a
   vector, rather than a matrix.  (As a consequence, in addition to
   being faster, this new version of the application will require less
   memory.)  Here is the revised program:
  </p><pre class="programlisting">  // Create the data cube.
  Matrix&lt;value_type&gt; data(npulse, nrange);
  Vector&lt;value_type&gt; tmp(nrange);            // tmp is now a vector

  // Create the pulse replica
  Vector&lt;value_type&gt; replica(nrange);

  // Define the FFT typedefs.
  typedef Fft&lt;const_Vector, value_type, value_type, fft_fwd, by_reference&gt;
		for_fft_type;
  typedef Fft&lt;const_Vector, value_type, value_type, fft_inv, by_reference&gt;
		inv_fft_type;

  // Create the FFT objects.
  for_fft_type  for_fft(Domain&lt;1&gt;(nrange), 1.0);
  inv_fft_type  inv_fft(Domain&lt;1&gt;(nrange), 1.0/(nrange));

  // Initialize data to zero
  data    = value_type();
  replica = value_type();

  // Before fast convolution, convert the replica into the
  // frequency domain
  for_fft(replica);

  // Perform fast convolution:
  for (index_type r=0; r &lt; nrange; ++r)
  {
    for_fft(data.row(r), tmp);
    tmp *= replica;
    inv_fft(tmp, data.row(r));
  }</pre><p>
   The following graph shows that the new "interleaved"
   formulation is faster than the original "phased" approach
   for large data sets.  For smaller data sets (where all of the data
   fits in the cache anyhow), the original method is faster because
   performing all of the FFTs at once is faster than performing them
   one by one.
  </p><div class="mediaobject" align="center"><img src="images/par/fastconv-cache.png" align="middle"></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="chap-serial.html">Prev</a> </td><td width="20%" align="center"><a accesskey="u" href="chap-serial.html">Up</a></td><td width="40%" align="right"> <a accesskey="n" href="sec-io-user-spec-storage.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Chapter 7. Fast Convolution </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> 7.3. Performing I/O with User-Specified Storage</td></tr></table></div></body></html>
